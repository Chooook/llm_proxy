import asyncio
import json
from typing import Dict, Callable, Awaitable

import aioredis
from loguru import logger

from settings import settings


class TaskProcessingError(Exception):
    pass


logger.add('worker.log', level=settings.LOGLEVEL, rotation='10 MB')

task_handlers: Dict[str, Callable[[str, aioredis.Redis], Awaitable[None]]] = {}

async def main():
    register_handlers()

    if not task_handlers:
        logger.error("âŒ ĞĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¾Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡!")
        return

    redis = aioredis.Redis.from_url(
        f'redis://{settings.HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}',
        decode_responses=True
    )
    asyncio.create_task(cleanup_dlq(redis))
    try:
        await worker_loop(redis)
    finally:
        await redis.close()


def register_handlers():
    """Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡"""
    try:
        import llama_cpp
        task_handlers['generate_local'] = _handle_generate_local_task
        logger.info("âœ… LLM Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ·Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
    except ImportError:
        logger.warning(
            "âš ï¸ LLM Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿ĞµĞ½: Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹")


async def _handle_generate_local_task(task_id: str, redis: aioredis.Redis):
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡ Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ¾Ğ¼"""
    try:
        from llama_cpp import (Llama,
                               ChatCompletionRequestUserMessage,
                               ChatCompletionRequestSystemMessage)
    except ImportError:
        await mark_task_failed(
            redis,
            task_id,
            "LLM Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°: Ğ¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ğ²ÑƒÑÑ‚ Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸"
        )
        raise TaskProcessingError("LLM Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ½Ğµ ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ñ‹")

    task_data = await redis.get(f'task:{task_id}')
    if not task_data:
        logger.warning(f'âš ï¸ Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° {task_id} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°')
        return

    # Ğ›ĞµĞ½Ğ¸Ğ²Ğ°Ñ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    if not hasattr(_handle_generate_local_task, 'llm'):
        try:
            _handle_generate_local_task.llm = Llama(
                model_path=settings.MODEL_PATH,
                n_ctx=65536,
                n_thread=12,
                n_batch=512,
                verbose=False
            )
            logger.info('âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ LLM Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ°')
        except Exception as e:
            await mark_task_failed(
                redis,
                task_id,
                f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {str(e)}"
            )
            raise TaskProcessingError(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {e}")

    task = json.loads(task_data)
    prompt = task['prompt']
    logger.debug(f'ğŸ§  ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½ prompt: {prompt}')
    try:
        system_message: ChatCompletionRequestSystemMessage = {
            "role": "system",
            "content": "Ğ¢Ñ‹ â€” Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰Ğ½Ğ¸Ğº, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ Ğ´Ğ°Ñ‘Ñ‚ ĞºÑ€Ğ°Ñ‚ĞºĞ¸Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹.",
        }
        user_message = ChatCompletionRequestUserMessage(
            role="user",
            content=prompt
        )
        output = _handle_generate_local_task.llm.create_chat_completion(
            messages=[system_message, user_message],
            max_tokens=512,
        )
        result = output['choices'][0]['message']['content'].strip()
        logger.debug(f'ğŸ§  Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: {result}')

        task['status'] = 'completed'
        task['result'] = result
        await redis.setex(f'task:{task_id}', 86400, json.dumps(task))
        logger.info(f'âœ… Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° {task_id} Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ°')

    except Exception as e:
        await mark_task_failed(
            redis,
            task_id,
            f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ LLM: {str(e)}"
        )
        raise


async def _handle_generate_api_task(task_id: str, redis: aioredis.Redis):
    # TODO
    pass


async def process_task(task_id: str, redis: aioredis.Redis):
    """ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ·Ğ°Ğ´Ğ°Ñ‡"""
    task_data = await redis.get(f'task:{task_id}')
    if not task_data:
        logger.warning(f'âš ï¸ Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° {task_id} Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°')
        return

    task = json.loads(task_data)
    handler = task_handlers.get(task['type'])

    if not handler:
        await mark_task_failed(
            redis,
            task_id,
            f"ĞĞµĞ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğ¹ Ñ‚Ğ¸Ğ¿ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸: {task['type']}"
        )
        return

    try:
        await handler(task_id, redis)
    except Exception as e:
        logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ {task_id}: {str(e)}")
        retries = await redis.hincrby(f'task:{task_id}', 'retries', 1)
        if retries > 3:
            await redis.rpush('dead_letters', task_id)
            await redis.lrem('processing_queue', 1, task_id)
            await mark_task_failed(redis, task_id, "ĞŸÑ€ĞµĞ²Ñ‹ÑˆĞµĞ½Ğ¾ Ñ‡Ğ¸ÑĞ»Ğ¾ Ğ¿Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğº")
        else:
            await redis.rpush('task_queue', task_id)


async def worker_loop(redis: aioredis.Redis):
    await recover_tasks(redis)

    while True:
        try:
            task_id = await redis.brpoplpush(
                'task_queue',
                'processing_queue',
                timeout=0
            )
            logger.info(f'ğŸ“¥ ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°: {task_id}')

            try:
                await process_task(task_id, redis)
                await redis.lrem('processing_queue', 1, task_id)
            except Exception as e:
                logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ {task_id}: {e}")
                await redis.rpush('task_queue', task_id)
                await redis.lrem('processing_queue', 1, task_id)

        except Exception as e:
            logger.error(f'âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ² worker: {e}')
            await asyncio.sleep(1)


async def recover_tasks(redis: aioredis.Redis):
    logger.info("ğŸ” Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ½ĞµĞ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ñ‡...")
    while True:
        task_id = await redis.rpop('processing_queue')
        if not task_id:
            break
        await redis.rpush('task_queue', task_id)
        logger.info(f"â™»ï¸ Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ°: {task_id}")


async def mark_task_failed(
        redis: aioredis.Redis, task_id: str, error_msg: str):
    task_data = await redis.get(f'task:{task_id}')
    if task_data:
        task = json.loads(task_data)
        task['status'] = 'failed'
        task['error'] = error_msg
        await redis.setex(f'task:{task_id}', 86400, json.dumps(task))


async def cleanup_dlq(redis: aioredis.Redis):
    while True:
        logger.info("ğŸ§¹ ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° dead_letters...")
        dlq_length = await redis.llen('dead_letters')
        if dlq_length > 50:
            tasks = await redis.lrange('dead_letters', 0, -1)
            for task_id in tasks:
                await redis.delete(f'task:{task_id}')
            await redis.delete('dead_letters')
        await asyncio.sleep(3600)


if __name__ == '__main__':
    asyncio.run(main())
